# =============================================================================
# Grafana Tempo Configuration
# =============================================================================
# 이 파일은 Grafana Tempo 트레이스 저장소의 동작을 정의합니다.
#
# 포트 설정 요약:
# - 3200: Tempo UI 및 Query API (Grafana에서 접근)
# - 9095: Tempo 내부 gRPC 서비스 (컴포넌트 간 통신)
# - 4417: OTLP gRPC 수신 (Collector에서 트레이스 데이터 수신)
# - 4418: OTLP HTTP 수신 (Collector에서 트레이스 데이터 수신)
#
# 주의: 개발환경에서는 Collector와 포트 구분을 위해 4417/4418 사용
#       실제 운영환경에서는 4317/4318 표준 포트 사용 권장
# =============================================================================

# Server: Tempo의 기본 HTTP/gRPC 서버 설정
# Tempo UI, Query API, 내부 컴포넌트 간 통신을 위한 서버
server:
  http_listen_port: 3200    # Tempo UI 및 HTTP Query API 포트
                           # Grafana에서 이 포트로 트레이스 조회 요청
  grpc_listen_port: 9095   # Tempo 내부 gRPC 서비스 포트
                           # Querier, Query-Frontend 등 내부 컴포넌트 간 통신
  http_listen_address: 0.0.0.0  # 모든 네트워크 인터페이스에서 수신

# Distributor: 외부에서 들어오는 트레이스 데이터를 수신하고 분산 처리
# OpenTelemetry Collector, 애플리케이션 등에서 직접 트레이스를 받는 진입점
distributor:
  receivers:
    # OTLP (OpenTelemetry Protocol) 수신기 설정
    # 표준 OpenTelemetry 프로토콜로 트레이스 데이터를 받음
    otlp:
      protocols:
        grpc:
          # OTLP gRPC 수신 엔드포인트
          # OpenTelemetry Collector가 이 포트로 트레이스 전송
          endpoint: 0.0.0.0:4417  # 개발환경: 4417 (Collector 4317과 구분)
                                 # 운영환경: 0.0.0.0:4317 (표준 포트) 권장
        http:
          # OTLP HTTP 수신 엔드포인트  
          # gRPC를 사용할 수 없는 환경에서 HTTP로 트레이스 전송
          endpoint: 0.0.0.0:4418  # 개발환경: 4418 (Collector 4318과 구분)
                                 # 운영환경: 0.0.0.0:4318 (표준 포트) 권장

# Ingester: 수신된 트레이스 데이터를 메모리에서 처리하고 저장소에 기록
# 실시간으로 들어오는 트레이스를 효율적으로 처리하기 위한 설정
ingester:
  max_block_duration: 5m      # 블록의 최대 지속 시간 (5분)
                             # 이 시간이 지나면 메모리의 데이터를 디스크로 플러시
  trace_idle_period: "30s"   # 트레이스가 완료되지 않은 상태로 대기하는 최대 시간
                            # 이 시간 후에는 불완전한 트레이스도 저장
  flush_check_period: "1m"   # 플러시가 필요한지 확인하는 주기 (1분마다)
  max_block_bytes: 1000000   # 블록의 최대 크기 (1MB)
                            # 이 크기에 도달하면 즉시 디스크로 플러시
  complete_block_timeout: "5m" # 블록 완성 대기 최대 시간 (5분)

# Storage: 트레이스 데이터의 영구 저장 설정
# 로컬 파일 시스템을 사용한 단순한 저장 방식 (개발/테스트용)
storage:
  trace:
    backend: local            # 저장 백엔드 타입 (local/s3/gcs/azure 등)
    local:
      path: /tmp/tempo/traces # 트레이스 블록이 저장될 로컬 디렉토리
                             # Docker 볼륨으로 마운트되어 데이터 영속성 확보
    # wal:                      # Write-Ahead Log (WAL) 설정 - 권한 문제로 주석처리
    #   path: /tmp/tempo/wal    # WAL 파일 저장 경로 (데이터 무결성 보장)
                               # 운영환경에서는 활성화 권장 (권한 설정 후)

# Query Frontend: 조회 성능 최적화 (선택적)
# 대용량 데이터셋에서 병렬 쿼리 처리를 통한 성능 향상
#query_frontend:
#  search:
#    concurrent_queries_per_tenant: 20  # 테넌트당 동시 실행 가능한 쿼리 수

# Compactor: 저장 효율성 향상 (선택적)
# 작은 블록들을 큰 블록으로 통합하여 저장 공간과 쿼리 성능 최적화
#compactor:
#  compaction:
#    compaction_window: 1h    # 압축 실행 주기 (1시간마다)
#    block_retention: 168h    # 블록 보관 기간 (7일)
#    compacted_block_retention: 24h  # 압축된 블록 보관 기간 (1일)